{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also load this from a json file\n",
    "test_data = {}\n",
    "test_data[\"dataset\"] = \"cifar10\" #cifar10\n",
    "test_data[\"normalize\"] = {\"mean\":120.707, \"std\":64.15} # None\n",
    "test_data[\"model_name\"] = \"cifar10_vgg16\"#\"cifar10_vgg16\" #cifar10\n",
    "\n",
    "# classifier config\n",
    "test_data[\"epochs\"] = 50#10\n",
    "test_data[\"post_epochs\"] = 4\n",
    "test_data[\"optim\"] = \"Adam\"\n",
    "test_data[\"optim_config\"] = tf.keras.optimizers.Adam().get_config()\n",
    "test_data[\"batch_size\"] = 64 #*8 # 512 batch_size behaves weirdly...\n",
    "\n",
    "# intervention config\n",
    "test_data[\"layer_key\"] = 'classifier' # which latent layer output should be used for embedding\n",
    "test_data[\"contraction_factors\"] = {\"all\": (1.0/2.0, 1.0/4.0)} # how much should the class points in the embedding be shifted to their center of mass\n",
    "test_data[\"shift_factors\"] = {3:[-4.,1.], 5:[0.,-3.]} # how much should the class points be shifted in a certain direction\n",
    "\n",
    "# embedder config\n",
    "test_data[\"embedding_approach\"] = \"umap\" # one of: [\"umap\", \"tsne\"]\n",
    "test_data[\"embedding_optim\"] = \"Adam\"\n",
    "test_data[\"embedding_optim_config\"] = tf.keras.optimizers.Adam().get_config()\n",
    "test_data[\"embedding_epochs\"] = 1 #1 for umap #5 for tsne\n",
    "test_data[\"embedding_batch_size\"] = 500\n",
    "test_data[\"embedding_subset\"] = 12 # subset that should be selected for training the embedding\n",
    "test_data[\"embedding_weight\"] = 0.4 # how much influence should the embedding loss have on training the classifier\n",
    "test_data[\"embedding_conf\"] = {'layer_dims': [300,100], 'alpha': 1.0, 'perplexities': 100, 'do_pretrain': True, 'beta_batch_size':256} #500,1000} # embedding approach speciffic configuration\n",
    "# test_data[\"embedding_conf\"] = {} # for unet we dont need any special config for now\n",
    "\n",
    "\n",
    "test_data[\"experiment_number\"] = 0\n",
    "# path = pathlib.Path().absolute()\n",
    "path = \"D:/ICG/Experiments/%s/Experiment-converged-net\"%test_data[\"dataset\"]\n",
    "# path = \"D:/ICG/Experiments/%s/Experiment-tsne-embepochs/Experiment-embepoch\"%meta_data[\"dataset\"]\n",
    "# path = \"D:/ICG/Experiments/%s/Experiment-tsne-layers/Experiment-layer\"%meta_data[\"dataset\"]\n",
    "\n",
    "test_data[\"base_path\"] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.optimizers.Adam().get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding features:\n",
    "# model_name ?\n",
    "# normalize: mean, std\n",
    "# epochs\n",
    "# post_epochs\n",
    "# optim ?\n",
    "# optim_config: learning_rate, decay, par1, par2, par3, par4\n",
    "# batch_size\n",
    "# layer_key ?\n",
    "# contraction_factors: all + 1 col per class\n",
    "# shift_factors: all + 1 col per class\n",
    "# embedding_approach ?\n",
    "# embedding_optim ?\n",
    "# embedding_optim_config: learning_rate, decay, par1, par2, par3, par4\n",
    "# embedding_epochs\n",
    "# embedding_batch_size\n",
    "# embedding_subset\n",
    "# embedding_weight\n",
    "# embedding_conf: layer_dims_1, layer_dims_2, layer_dims_3, alpha, perplexities, do_pretrain, beta_batch_size\n",
    "\n",
    "\n",
    "\n",
    "# color coding features:\n",
    "# model_name\n",
    "# optim\n",
    "# layer_key ?\n",
    "# embedding_approach ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_cols(nr_classes):\n",
    "#     cols = [\"normalize_mean\", \"normalize_std\", \"model_name\", \"epochs\", \"post_epochs\", \"optim\", \"optim_config_lr\", \"optim_config_decay\", \"optim_config_par1\", \"optim_config_par2\", \"optim_config_par3\", \"optim_config_par4\", \"batch_size\", \"layer_key\", \"embedding_approach\", \"embedding_optim\", \"embedding_optim_config_lr\", \"embedding_optim_config_decay\", \"embedding_optim_config_par1\", \"embedding_optim_config_par2\", \"embedding_optim_config_par3\", \"embedding_optim_config_par4\", \"embedding_epochs\", \"embedding_batch_size\", \"embedding_subset\", \"embedding_weight\", \"embedding_conf_layer_dims_1\", \"embedding_conf_layer_dims_2\", \"embedding_conf_layer_dims_3\", \"embedding_conf_par1\", \"embedding_conf_par2\", \"embedding_conf_do_pretrain\", \"embedding_conf_beta_batch_size\"]\n",
    "    cols = [\"dataset\"\n",
    "        ,\"normalize_mean\"\n",
    "        ,\"normalize_std\"\n",
    "        ,\"model_name\"\n",
    "        ,\"epochs\"\n",
    "        ,\"post_epochs\"\n",
    "        ,\"optim\"\n",
    "        ,\"optim_config_name\"\n",
    "        ,\"optim_config_learning_rate\"\n",
    "        ,\"optim_config_decay\"\n",
    "        ,\"optim_config_beta_1\"\n",
    "        ,\"optim_config_beta_2\"\n",
    "        ,\"optim_config_epsilon\"\n",
    "        ,\"optim_config_amsgrad\"\n",
    "        ,\"optim_config_initial_accumulator_value\"\n",
    "        ,\"optim_config_initial_rho\"\n",
    "        ,\"optim_config_initial_momentum\"\n",
    "        ,\"optim_config_initial_mnesterov\"\n",
    "        ,\"batch_size\"\n",
    "        ,\"layer_key\"\n",
    "        ,\"embedding_approach\"\n",
    "        ,\"embedding_optim\"\n",
    "        ,\"embedding_optim_config_name\"\n",
    "        ,\"embedding_optim_config_learning_rate\"\n",
    "        ,\"embedding_optim_config_decay\"\n",
    "        ,\"embedding_optim_config_beta_1\"\n",
    "        ,\"embedding_optim_config_beta_2\"\n",
    "        ,\"embedding_optim_config_epsilon\"\n",
    "        ,\"embedding_optim_config_amsgrad\"\n",
    "        ,\"embedding_optim_config_initial_accumulator_value\"\n",
    "        ,\"embedding_optim_config_initial_rho\"\n",
    "        ,\"embedding_optim_config_initial_momentum\"\n",
    "        ,\"embedding_optim_config_initial_mnesterov\"\n",
    "        ,\"embedding_epochs\"\n",
    "        ,\"embedding_batch_size\"\n",
    "        ,\"embedding_subset\"\n",
    "        ,\"embedding_weight\"\n",
    "        ,\"experiment_number\"\n",
    "        ,\"base_path\"\n",
    "        ,\"embedding_conf_layer_dims_1\"\n",
    "        ,\"embedding_conf_layer_dims_2\"\n",
    "        ,\"embedding_conf_layer_dims_3\"\n",
    "        ,\"embedding_conf_alpha\"\n",
    "        ,\"embedding_conf_perplexities\"\n",
    "        ,\"embedding_conf_do_pretrain\"\n",
    "        ,\"embedding_conf_beta_batch_size\"\n",
    "        ,\"embedding_conf_embedding_size\"\n",
    "       ]\n",
    "    \n",
    "    cols.append(\"contraction_factors_all_1\")\n",
    "    cols.append(\"contraction_factors_all_2\")\n",
    "    \n",
    "    for c in range(1, nr_classes+1):\n",
    "        cols.append(\"contraction_factors_%d_1\"%c)\n",
    "        cols.append(\"contraction_factors_%d_2\"%c)\n",
    "    \n",
    "    cols.append(\"shift_factors_all_1\")\n",
    "    cols.append(\"shift_factors_all_2\")\n",
    "\n",
    "    for c in range(1, nr_classes+1):\n",
    "        cols.append(\"shift_factors_%d_1\"%c)\n",
    "        cols.append(\"shift_factors_%d_2\"%c)\n",
    "        \n",
    "    return cols\n",
    "\n",
    "import numpy as np\n",
    "def map_dict_to_table(meta_data, nr_classes):\n",
    "    cols = get_cols(nr_classes)\n",
    "    df = pd.DataFrame(list(np.zeros((1,len(cols)), dtype=\"int32\")), columns=cols)\n",
    "    \n",
    "    for key in meta_data:\n",
    "        val = meta_data[key]\n",
    "        if type(val) is dict:\n",
    "            for key_sub in val:\n",
    "                val_sub = val[key_sub]\n",
    "                if type(val_sub) is list or type(val_sub) is tuple:\n",
    "                    for i_list in range(len(val_sub)):\n",
    "                        df[\"%s_%s_%d\"%(key, key_sub, i_list+1)] = val_sub[i_list]\n",
    "                else:\n",
    "                    df[\"%s_%s\"%(key, key_sub)] = val_sub\n",
    "        else:\n",
    "            df[key] = val\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>normalize_mean</th>\n",
       "      <th>normalize_std</th>\n",
       "      <th>model_name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>post_epochs</th>\n",
       "      <th>optim</th>\n",
       "      <th>optim_config_name</th>\n",
       "      <th>optim_config_learning_rate</th>\n",
       "      <th>optim_config_decay</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_factors_6_1</th>\n",
       "      <th>shift_factors_6_2</th>\n",
       "      <th>shift_factors_7_1</th>\n",
       "      <th>shift_factors_7_2</th>\n",
       "      <th>shift_factors_8_1</th>\n",
       "      <th>shift_factors_8_2</th>\n",
       "      <th>shift_factors_9_1</th>\n",
       "      <th>shift_factors_9_2</th>\n",
       "      <th>shift_factors_10_1</th>\n",
       "      <th>shift_factors_10_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>120.707</td>\n",
       "      <td>64.15</td>\n",
       "      <td>cifar10_vgg16</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  normalize_mean  normalize_std     model_name  epochs  post_epochs  \\\n",
       "0  cifar10         120.707          64.15  cifar10_vgg16      50            4   \n",
       "\n",
       "  optim optim_config_name  optim_config_learning_rate  optim_config_decay  \\\n",
       "0  Adam              Adam                       0.001                 0.0   \n",
       "\n",
       "   ...  shift_factors_6_1  shift_factors_6_2  shift_factors_7_1  \\\n",
       "0  ...                  0                  0                  0   \n",
       "\n",
       "   shift_factors_7_2  shift_factors_8_1  shift_factors_8_2  shift_factors_9_1  \\\n",
       "0                  0                  0                  0                  0   \n",
       "\n",
       "   shift_factors_9_2  shift_factors_10_1 shift_factors_10_2  \n",
       "0                  0                   0                  0  \n",
       "\n",
       "[1 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict_to_table(test_data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "experiment_folders = glob(\"G:\\\\Uni4ICG\\\\PLI Experiments/*/*/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "meta_data_list = []\n",
    "for experiment_folder in experiment_folders:\n",
    "    file = open(\"%s/meta_data.json\"%experiment_folder, \"r\")\n",
    "    data = json.load(file)\n",
    "    meta_data_list.append(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = get_cols(10)\n",
    "df = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(meta_data_list)):\n",
    "    meta_data_df = map_dict_to_table(meta_data_list[i], 10)\n",
    "    df = df.append(meta_data_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>normalize_mean</th>\n",
       "      <th>normalize_std</th>\n",
       "      <th>model_name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>post_epochs</th>\n",
       "      <th>optim_config_name</th>\n",
       "      <th>optim_config_learning_rate</th>\n",
       "      <th>optim_config_decay</th>\n",
       "      <th>optim_config_beta_1</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_factors_6_1</th>\n",
       "      <th>shift_factors_6_2</th>\n",
       "      <th>shift_factors_7_1</th>\n",
       "      <th>shift_factors_7_2</th>\n",
       "      <th>shift_factors_8_1</th>\n",
       "      <th>shift_factors_8_2</th>\n",
       "      <th>shift_factors_9_1</th>\n",
       "      <th>shift_factors_9_2</th>\n",
       "      <th>shift_factors_10_1</th>\n",
       "      <th>shift_factors_10_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cifar10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dataset normalize_mean normalize_std model_name epochs post_epochs  \\\n",
       "0    cifar10              0             0    cifar10      5           4   \n",
       "1    cifar10              0             0    cifar10      5           4   \n",
       "2    cifar10              0             0    cifar10      5           4   \n",
       "3    cifar10              0             0    cifar10      5           4   \n",
       "4    cifar10              0             0    cifar10      5           4   \n",
       "..       ...            ...           ...        ...    ...         ...   \n",
       "455  cifar10              0             0    cifar10      5           4   \n",
       "456  cifar10              0             0    cifar10      5           4   \n",
       "457  cifar10              0             0    cifar10      5           4   \n",
       "458  cifar10              0             0    cifar10      5           4   \n",
       "459  cifar10              0             0    cifar10      5           4   \n",
       "\n",
       "    optim_config_name  optim_config_learning_rate  optim_config_decay  \\\n",
       "0                Adam                       0.001                 0.0   \n",
       "1                Adam                       0.001                 0.0   \n",
       "2                Adam                       0.001                 0.0   \n",
       "3                Adam                       0.001                 0.0   \n",
       "4                Adam                       0.001                 0.0   \n",
       "..                ...                         ...                 ...   \n",
       "455              Adam                       0.001                 0.0   \n",
       "456              Adam                       0.001                 0.0   \n",
       "457              Adam                       0.001                 0.0   \n",
       "458              Adam                       0.001                 0.0   \n",
       "459              Adam                       0.001                 0.0   \n",
       "\n",
       "     optim_config_beta_1  ...  shift_factors_6_1  shift_factors_6_2  \\\n",
       "0                    0.9  ...                  0                  0   \n",
       "1                    0.9  ...                  0                  0   \n",
       "2                    0.9  ...                  0                  0   \n",
       "3                    0.9  ...                  0                  0   \n",
       "4                    0.9  ...                  0                  0   \n",
       "..                   ...  ...                ...                ...   \n",
       "455                  0.9  ...                  0                  0   \n",
       "456                  0.9  ...                  0                  0   \n",
       "457                  0.9  ...                  0                  0   \n",
       "458                  0.9  ...                  0                  0   \n",
       "459                  0.9  ...                  0                  0   \n",
       "\n",
       "    shift_factors_7_1 shift_factors_7_2 shift_factors_8_1 shift_factors_8_2  \\\n",
       "0                   0                 0                 0                 0   \n",
       "1                   0                 0                 0                 0   \n",
       "2                   0                 0                 0                 0   \n",
       "3                   0                 0                 0                 0   \n",
       "4                   0                 0                 0                 0   \n",
       "..                ...               ...               ...               ...   \n",
       "455                 0                 0                 0                 0   \n",
       "456                 0                 0                 0                 0   \n",
       "457                 0                 0                 0                 0   \n",
       "458                 0                 0                 0                 0   \n",
       "459                 0                 0                 0                 0   \n",
       "\n",
       "    shift_factors_9_1 shift_factors_9_2 shift_factors_10_1 shift_factors_10_2  \n",
       "0                   0                 0                  0                  0  \n",
       "1                   0                 0                  0                  0  \n",
       "2                   0                 0                  0                  0  \n",
       "3                   0                 0                  0                  0  \n",
       "4                   0                 0                  0                  0  \n",
       "..                ...               ...                ...                ...  \n",
       "455                 0                 0                  0                  0  \n",
       "456                 0                 0                  0                  0  \n",
       "457                 0                 0                  0                  0  \n",
       "458                 0                 0                  0                  0  \n",
       "459                 0                 0                  0                  0  \n",
       "\n",
       "[460 rows x 88 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"normalize\", \"optim\", \"embedding_optim\", 'base_path'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'normalize_mean', 'normalize_std', 'model_name', 'epochs',\n",
       "       'post_epochs', 'optim_config_name', 'optim_config_learning_rate',\n",
       "       'optim_config_decay', 'optim_config_beta_1', 'optim_config_beta_2',\n",
       "       'optim_config_epsilon', 'optim_config_amsgrad',\n",
       "       'optim_config_initial_accumulator_value', 'optim_config_initial_rho',\n",
       "       'optim_config_initial_momentum', 'optim_config_initial_mnesterov',\n",
       "       'batch_size', 'layer_key', 'embedding_approach',\n",
       "       'embedding_optim_config_name', 'embedding_optim_config_learning_rate',\n",
       "       'embedding_optim_config_decay', 'embedding_optim_config_beta_1',\n",
       "       'embedding_optim_config_beta_2', 'embedding_optim_config_epsilon',\n",
       "       'embedding_optim_config_amsgrad',\n",
       "       'embedding_optim_config_initial_accumulator_value',\n",
       "       'embedding_optim_config_initial_rho',\n",
       "       'embedding_optim_config_initial_momentum',\n",
       "       'embedding_optim_config_initial_mnesterov', 'embedding_epochs',\n",
       "       'embedding_batch_size', 'embedding_subset', 'embedding_weight',\n",
       "       'experiment_number', 'embedding_conf_layer_dims_1',\n",
       "       'embedding_conf_layer_dims_2', 'embedding_conf_layer_dims_3',\n",
       "       'embedding_conf_alpha', 'embedding_conf_perplexities',\n",
       "       'embedding_conf_do_pretrain', 'embedding_conf_beta_batch_size',\n",
       "       'embedding_conf_embedding_size', 'contraction_factors_all_1',\n",
       "       'contraction_factors_all_2', 'contraction_factors_1_1',\n",
       "       'contraction_factors_1_2', 'contraction_factors_2_1',\n",
       "       'contraction_factors_2_2', 'contraction_factors_3_1',\n",
       "       'contraction_factors_3_2', 'contraction_factors_4_1',\n",
       "       'contraction_factors_4_2', 'contraction_factors_5_1',\n",
       "       'contraction_factors_5_2', 'contraction_factors_6_1',\n",
       "       'contraction_factors_6_2', 'contraction_factors_7_1',\n",
       "       'contraction_factors_7_2', 'contraction_factors_8_1',\n",
       "       'contraction_factors_8_2', 'contraction_factors_9_1',\n",
       "       'contraction_factors_9_2', 'contraction_factors_10_1',\n",
       "       'contraction_factors_10_2', 'shift_factors_all_1',\n",
       "       'shift_factors_all_2', 'shift_factors_1_1', 'shift_factors_1_2',\n",
       "       'shift_factors_2_1', 'shift_factors_2_2', 'shift_factors_3_1',\n",
       "       'shift_factors_3_2', 'shift_factors_4_1', 'shift_factors_4_2',\n",
       "       'shift_factors_5_1', 'shift_factors_5_2', 'shift_factors_6_1',\n",
       "       'shift_factors_6_2', 'shift_factors_7_1', 'shift_factors_7_2',\n",
       "       'shift_factors_8_1', 'shift_factors_8_2', 'shift_factors_9_1',\n",
       "       'shift_factors_9_2', 'shift_factors_10_1', 'shift_factors_10_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalize_mean</th>\n",
       "      <th>normalize_std</th>\n",
       "      <th>epochs</th>\n",
       "      <th>post_epochs</th>\n",
       "      <th>optim_config_learning_rate</th>\n",
       "      <th>optim_config_decay</th>\n",
       "      <th>optim_config_beta_1</th>\n",
       "      <th>optim_config_beta_2</th>\n",
       "      <th>optim_config_epsilon</th>\n",
       "      <th>optim_config_amsgrad</th>\n",
       "      <th>...</th>\n",
       "      <th>shift_factors_9_2</th>\n",
       "      <th>shift_factors_10_1</th>\n",
       "      <th>shift_factors_10_2</th>\n",
       "      <th>dataset_cifar10</th>\n",
       "      <th>model_name_cifar10</th>\n",
       "      <th>optim_config_name_Adam</th>\n",
       "      <th>layer_key_classifier</th>\n",
       "      <th>embedding_approach_tsne</th>\n",
       "      <th>embedding_approach_umap</th>\n",
       "      <th>embedding_optim_config_name_Adam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>460 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     normalize_mean  normalize_std  epochs  post_epochs  \\\n",
       "0                 0              0       5            4   \n",
       "1                 0              0       5            4   \n",
       "2                 0              0       5            4   \n",
       "3                 0              0       5            4   \n",
       "4                 0              0       5            4   \n",
       "..              ...            ...     ...          ...   \n",
       "455               0              0       5            4   \n",
       "456               0              0       5            4   \n",
       "457               0              0       5            4   \n",
       "458               0              0       5            4   \n",
       "459               0              0       5            4   \n",
       "\n",
       "     optim_config_learning_rate  optim_config_decay  optim_config_beta_1  \\\n",
       "0                         0.001                 0.0                  0.9   \n",
       "1                         0.001                 0.0                  0.9   \n",
       "2                         0.001                 0.0                  0.9   \n",
       "3                         0.001                 0.0                  0.9   \n",
       "4                         0.001                 0.0                  0.9   \n",
       "..                          ...                 ...                  ...   \n",
       "455                       0.001                 0.0                  0.9   \n",
       "456                       0.001                 0.0                  0.9   \n",
       "457                       0.001                 0.0                  0.9   \n",
       "458                       0.001                 0.0                  0.9   \n",
       "459                       0.001                 0.0                  0.9   \n",
       "\n",
       "     optim_config_beta_2  optim_config_epsilon  optim_config_amsgrad  ...  \\\n",
       "0                  0.999          1.000000e-07                 False  ...   \n",
       "1                  0.999          1.000000e-07                 False  ...   \n",
       "2                  0.999          1.000000e-07                 False  ...   \n",
       "3                  0.999          1.000000e-07                 False  ...   \n",
       "4                  0.999          1.000000e-07                 False  ...   \n",
       "..                   ...                   ...                   ...  ...   \n",
       "455                0.999          1.000000e-07                 False  ...   \n",
       "456                0.999          1.000000e-07                 False  ...   \n",
       "457                0.999          1.000000e-07                 False  ...   \n",
       "458                0.999          1.000000e-07                 False  ...   \n",
       "459                0.999          1.000000e-07                 False  ...   \n",
       "\n",
       "     shift_factors_9_2  shift_factors_10_1  shift_factors_10_2  \\\n",
       "0                    0                   0                   0   \n",
       "1                    0                   0                   0   \n",
       "2                    0                   0                   0   \n",
       "3                    0                   0                   0   \n",
       "4                    0                   0                   0   \n",
       "..                 ...                 ...                 ...   \n",
       "455                  0                   0                   0   \n",
       "456                  0                   0                   0   \n",
       "457                  0                   0                   0   \n",
       "458                  0                   0                   0   \n",
       "459                  0                   0                   0   \n",
       "\n",
       "     dataset_cifar10  model_name_cifar10  optim_config_name_Adam  \\\n",
       "0                  1                   1                       1   \n",
       "1                  1                   1                       1   \n",
       "2                  1                   1                       1   \n",
       "3                  1                   1                       1   \n",
       "4                  1                   1                       1   \n",
       "..               ...                 ...                     ...   \n",
       "455                1                   1                       1   \n",
       "456                1                   1                       1   \n",
       "457                1                   1                       1   \n",
       "458                1                   1                       1   \n",
       "459                1                   1                       1   \n",
       "\n",
       "     layer_key_classifier  embedding_approach_tsne  embedding_approach_umap  \\\n",
       "0                       1                        1                        0   \n",
       "1                       1                        1                        0   \n",
       "2                       1                        1                        0   \n",
       "3                       1                        1                        0   \n",
       "4                       1                        1                        0   \n",
       "..                    ...                      ...                      ...   \n",
       "455                     1                        0                        1   \n",
       "456                     1                        0                        1   \n",
       "457                     1                        0                        1   \n",
       "458                     1                        0                        1   \n",
       "459                     1                        0                        1   \n",
       "\n",
       "     embedding_optim_config_name_Adam  \n",
       "0                                   1  \n",
       "1                                   1  \n",
       "2                                   1  \n",
       "3                                   1  \n",
       "4                                   1  \n",
       "..                                ...  \n",
       "455                                 1  \n",
       "456                                 1  \n",
       "457                                 1  \n",
       "458                                 1  \n",
       "459                                 1  \n",
       "\n",
       "[460 rows x 89 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = [\"dataset\", \"model_name\", \"optim_config_name\", \"layer_key\", \"embedding_approach\", \"embedding_optim_config_name\"] # loop over categorical entries an perform one-hot encoding\n",
    "for col in cat_cols:\n",
    "    one_hot = pd.get_dummies(df[col], prefix=col)\n",
    "    df = pd.concat([df, one_hot], axis=1)\n",
    "    \n",
    "df = df.drop(columns=cat_cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"embedding_conf_do_pretrain\"] = df[\"embedding_conf_do_pretrain\"].astype(int)\n",
    "df[\"optim_config_amsgrad\"] = df[\"optim_config_amsgrad\"].astype(int)\n",
    "df[\"embedding_conf_do_pretrain\"] = df[\"embedding_conf_do_pretrain\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: one-hot encoding; umap embedding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UMAP()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reducer = umap.UMAP()\n",
    "reducer.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xd75b045a30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlNElEQVR4nO3dd3xV9f3H8dfn3NxMwkwYxYEDB2pBiliLdWuR+hNt66httY5qtfRXW1tHaRVnrRb3qKgUtY46cNY96vi1IqEuKoKIVkUCgcjIIDfJ+f7+SEBC7kzuOsn7+Xjkkdzz/d5zPrm5vDn3e875HnPOISIiweXlugAREekeBbmISMApyEVEAk5BLiIScApyEZGAK8jFRisqKtyIESNysWkRkcCaN2/eSudc5ebLcxLkI0aMoKqqKhebFhEJLDP7b7TlGloREQk4BbmISMApyEVEAk5BLiIScDk52CkimeP8BlzkTcDHivbErDDXJUmGKchFehB/zY3QeO3Gxw7DlZ2OV35m7oqSjFOQi/QAzjncin3ALd+8Bepvwg9tg1c6OSe1SeZpjFykB3CrTowS4ptYd03WapHsU5CLBJxzDlr+maDTiuwUIzmhIBcJOteYuI8NyXwdkjMKcpGgs6LEffqelfk6JGcU5CIBZxYCb4c4PUJ4Jd/OWj2SfQpykZ6g4gGgLHrbgDuzWopkn4JcpAfwvBJsyL+h/DLwtgYGQtEhUPEPvKI9cl2eZJjOIxfpIcwMK/selH0v16VIlmmPXEQk4BTkIhniXCPO/6LtPG+RDNLQikiaOb8O98Xp0Dzny2VFp+ANODuHVUlPpj1ykTRztcd2CHEAmm7Dr941NwVJj6cgF0kj1/IhtCyK0RrBr9YZJJJ+CnKRNHItHyfosQa/4bFslCK9iIJcJJ0Kdkncp2565uuQXkVBLpJGXsFQoDR+J9eclVqk91CQi6Rb5Zz47SW6wYOkl4JcJM28UBEMeDdGaxnW57Ss1iM9n4JcJAO8oiK8oYug7Cyw/mB9ofR4bPCLmNc/1+VJD6MLgkQyyCs/Dcq1By6ZpT1yEZGAU5CLiAScglxEJOAU5CIiAZd0kJvZTDNbYWbzN1k2zcyWmtlb7V+TMlOmiIjEksoe+SxgYpTlVzvnxrR/PZmeskREJFlJB7lz7hWgNoO1iIhIF6RjjHyKmb3TPvQyIFYnMzvVzKrMrKqmpiYNmxUREeh+kN8MbAeMAZYBMad1c87NcM6Nc86Nq6ys7OZmRURkg24FuXNuuXOu1TnnA7cC49NTloiIJKtbQW5mwzZ5eCQwP1ZfEUkP32/Ab12d6zIkjyQ914qZ3QvsB1SY2WfABcB+ZjYGcMDHgCaVEMkQv/VzqDkMqGt7DFB4MN7AG3NZluSBpIPcOff9KItvT2MtIhKDcw5q9qdtn2kTkefwq/fHG/pSTuqS/KArO0UCwDU8TKcQ32gpfvV3slmO5BkFuUgQNCe46xDz8Ruez0opkn8U5CJBULhf4j7rLs14GZKfFOQiAeCVHppEr8aM1yH5SUEuEhT9n43fXhxtKiTpDRTkIgHhFY+AiliXahRC+TnZLEfyiIJcJEC8gkIY/D4UTgTCbV/h/WHw63heSa7LkxzRzZdFAsbzPBh4Xa7LkDyiPXIRkYBTkIuIBJyCXEQk4BTkIiIBpyAXEQk4BbmISMApyEVEAk5BLiIScApyEZGAU5CLiAScgrwL6tc2cMGRf+TQ4mOZVHIcfzrlJlpbW4k0NbO6Zg2+7+e6RBHpRcy5WLePypxx48a5qqqqrG83HRZWLWbK+PPi9iksKWTKDSdz6IkHZKkqEekNzGyec27c5su1R56CutX1CUMcINIY4aqTb2be8+9koSoR6e0U5CmYdcF9KfW/fsqtGapERORLCvIUvPvygpT6L11UnaFKRES+pCBPwVajtkj5OWu/qMtAJSIiX1KQp+CMa36c8nOev+vl9BciIrIJBXkKBgzuzzHnTE7pOQb4vs+iqsVM+84VfKfyRCb3O56ph13Gik9rMlOoiPQqOv2wC2b+7h7uvezhpPoO+soAVn3+RfRGg2tfu4RRe+2YxupEpKeKdfqhgryL6tc2cP+Vj/H643NZ8s4n0TsZkODlLR9QxuxVs9Jdnoj0QDqPPM3K+pZy4sXHcstb0/nljNMo7Ve6sa28opxDfrxvwhAHWPdFPcv/qyEWEem6glwX0BNMOuUgJp1yUIdlv5gwNbknGzQ1RjJQVdctfnMJ15xxK3W1dex3zN58/7wjKCopynVZIhKD9sgzZPjIYUn1Ky0vZosdkuubDedOvJjTv3YOC+csZukH1dx9yYMcOeDHrFy6KteliUgMCvIMOePaE5PqN2322XheZv4MzZFmZp1/Lz8bfw7XTbmN1tbWuP1nX/cE857tPK1Ac6SFad/9U0ZqFJHuSzpBzGymma0ws/mbLBtoZs+Z2Qft3wdkpszg6dOvjN/d/0vMOrcVlobZ55hv8NePbmT3A3bLyPY/ef8zJpUcx92XzGZR1RIev+kZJoaPZe4zb0bt/+hNT3PzmXfEXN/CuYszUqeIdF/SZ62Y2T5AHXCnc27X9mVXALXOucvN7FxggHPunETr6glnrSTLOcebL85n9co17DlpLGXlpYmflAaH9/8RjWvXR217uvk+QqHQxsdfLF/N0cN+knCdz/kPpK0+EUldt89acc69AtRutngysGE37g7giK4W2FOZGWMP3I0Djtm7WyHe2tLKbef+lUOLj+Vg7yi+FT6Gu6bdH7Vvw7rGmCEOMDF8LA9d/Tgb/hN/6W//l3D7w0cO7VrhIpJx3R2cHeKcWwbQ/n1wrI5mdqqZVZlZVU2NTrdL1UVHT+dvVzxKS6RtnNtv9bnzogc4fMDxnfom8ynrz2fdyf1/egyAj+d/mrD/Na9dkmLFIpItWTvY6Zyb4Zwb55wbV1lZma3N9ggrPqnhn4/MjdrWuKaRE3b4eYdlZX1L2y5GSuCeyx6itbWVMfvvErffd8/6Nv0r+yVdr4hkV3eDfLmZDQNo/76i+yXJ5j5KsMf8+eJqLvvhtR2WjT0w8UHU9fVN1K9pYN+jvhG33wnTjo3Z9snCpVxxwvVcc/otLPtoecJtikj6dTfIHwNOaP/5BODRbq5Pohi27ZCEfV665zXOnXgJq5a1zety+BkTEz7Hb/E5ZZdf8s4r77HzniOj9hk/aXdKyoo7Ps/3qfl8Jd+tPImTdz6T5+56hb/f8jzHbzeFa356SxK/kYikUypnrdwL7AdUAMuBC4BHgPuBrYBPgKOcc5sfEO2kN521ki6HFByN8xP/rfpV9uXWd6bTZ0AZRwz8MZGGxFeNhovCmGdENrvCtLisiLuW3LhxWOW5u17mxl/8hfrV9XHXd9UrF7Hb3jsn3K6IpCYdZ6183zk3zDkXds5t4Zy73Tm3yjl3oHNuZPv3hCEuXXPJE4nvFQpQv7qeB6Y/xsrPajnp4mMpLkt8aX1zU3OnEIe2A6rNTS0APP2XF7nqJ39OGOIA91w6O6laRSQ9dGVnQIyfuDvn3f2/Cfu1NLfy1O0vcsquv+TOaQ+AGZVbDsILpf6nLggXsKZmLQB/+d19tERaknre+vrYpz6KSPopyAPkgO9/kyca7iYUjv9na1jTSGR9Mw3rGllft759PvTUpyt2zjF8h2E8e+c/qF0WY071KCaedEDK2xKRrgtUkEeamrnxFzOZ+u3LePG+1/B9P9clZV1RcSGPrb2L7UaPiNpuZp1eF7/Vx29NLcgLSwr5yZU/4ooTbuD6n92W9PP6D+7LISfsl9K2RKR7AnNjiatP+zNP3vpCh2Wl/Uq479NbKOlTks7yAmPJu//l8h9dx6fvf064qAAzI1QQYl1t9Bs+h4sKNo55J7LX/4zj2HOP4JxDLmZ9fVPSNT3bej8WbYIZySvOOVz9fdAwC7zB0G8qXninXJclCcQ62BmI+cgv+9G1vHT3a52WN6xp5PeHX86fXrwwB1Xl3ra7bc2Mt6az8vNa1tSsZcudhnPr2Xfx6A1PR7+604xBwweyamniY9KvPzGP4SOHEVnfnHQ9W+z4FYV4APiRRqgdvcmCj2DV4fjFx+L1vyh3hUmX5f3QSlNTJGqIb/D2y+9lsZr8VPGVgWw3egSFRWEOOG7vmJfot7a0cujJByQ1hu2cY2HVh4SLwp0bo7xrQuEQZ8+akmrpkmV+89qOIb6p9ffht1ZntyBJi7wP8tvOvit+h+yPDOW15R/XYF70vWK/xWfh3A/51a0/ZcJ3xidc17uvvkfT+s7DKsWlxVz7r0uZcOR4vrL9UA44bm9mvD095kVFkkdWTYjfvu667NQhaZX3Qyura9bFbe8zoCxLlQTDkBGD41449Obz7/DWS/OZ9uBvWDBnEWcfdFHsMXDXdvA0XFxAQbjtrVJQWMD5D57FqD13YNpDv8nEryAZ4kcWAAmOd7j4/94kP+X9HvkPpn43brtm5etop/Hbx21vaW5l2pFXElkfYec9d+DOD2+ksDjK8Ek75zvCxWH+8Mzv+MPTU7l/2a2M3jf+JFuSpyKxhyg3KvtV5uuQtMv7IB+xy5ZsO3rrqG1n3zWFrXfeIssV5Tczizm0skGr7/PmC+8CMGBwP65//Q94BbHfCpHGCKO+vgOj9tqRUEGoQ9uCOYv43tCTOdg7ioNDR/Gr/c5nba326vKSV5GgQzle4TZZKUXSK++DHOCWN//Ej84/iqLSQryQx9ajtuCBmts5+Af75rq0vPPZB58nnJOlqaGJ9Q1ffsTe9qtbx92THxPldnQN6xr5zcEX8r97TWXNirarP3Hw7isL+OE2Z9DSnNxpjpI9VnwwEOvTVzHe0HnZLEfSKO/HyDc4ftrRHD/t6FyXkfeu+kkSsw86CG82nHLChcfyu8Mui3qe+ftzFrFsyXIi6yPceeEDLJy7mFXVtbSsj34z58Z163l65oscdtohXfodJDPM6wMD78J9cQq4Ta41KP4BXv8LcleYdFtgglwSW7tqHfNfW5CwX7g43Olsn7EH7sbRv5nM3Zc81Kn/utp6zpt0KauWfkFTY1NSszA+e8fLCvI8ZIVjYfAb0Pw20ArhMZgV5ros6SYFeQ8y+9q/JxWyfovP6H1HdVr+0bufxHzO0g+WpXSqZ0l5ceJOkhNmBVD4tYxvxzmHq/0pNP8DcOANh/434BXqYHm6BWKMXBKrrf4i6t50NBOO2IOyfp1P22yKMpXtRimerz/h8E5XEUsv4jfV4ZbvCM0vsfHN4y+F2iPxmz/IaW09kYK8B2isX8/pXzs7qb4FhQUxjzWU9o29F+2FUrv0vqhUe+S9le+3wBdjY3dY3TtPcfQjb+HX34kfmZ/2dWtoJUA+eve/nH/kldR8tpKBQ/sz9d4z+ddj83jo6ieSniv8oB98k61Hbdlp+Zy/z+P1x2OftTB+4ljmPPnvmJf/b6q4TzGVWw5Kqh7pgVYnmDe/9cPs1JEn/MZ/wpofd1zGEGzwU20HoNNAQR4QT972HFefOmPj45pPVnHmhN+ntI4hW1fyq9tOj9r2wFWPx5wZsaAwxLzn304qxL2QR79B5Yw5YNeUapMeJPJqgg695+Cq3/AyrP1JlJbluFWnYpX3pGU7GloJiE1DvCtK+5Zw6d/P6zQ7YWR9hGt+egtvv/SfmM91PlHnMy8uK+J7v55Mv8HlFJUWUVgcZuTYbbjgoV/z8HVP8udf38H/PfIGrS3RT1OU/ONcI651VVL/aceWYFit7GfdWHdwOOdihHi71qpuvs5f0h55ANRWJ393nmjCRQXcsfgG+lf07dT2x+Ov59XZc+I+3yvwaI4yna2Zsf3orTl12e18/mE1RSWFrPh0FWftdwGtrT6RxggPXfUEGPTpV8bwHYbxjcP3YPKUiZT1Le3W7yTp5a//P1g9BfjynqyOPlB+LlZ6VGrTE/f5NdTF+rTYH688Trj1IG79K0n0aiUdMaw98gAoKOz6H9or8Pj5Dad0CPH6tQ08fvMzXH78dbw6e07cUxaHjKjkmLMnU1Ta+eNwa6vP9ruPwMwYvv0wBn1lIJd9/xoa69Z3vJmzg7rV9Sx8YzF/+d29fG/Iybz3r4Vd/p0kPVzkDfxV38Ov3hVWn8imId6mDtb9DrcutfmMrOxoCHU+vRX7Ct7QN7pcb+D4HyfoYG2ngqaB9sgDoO/A8i49z/OM7/3y2zxyw1NcP+U2WiKtFBSGaG1pxfmORJ/qRu+3C7+eeQZ9B5Xz1O0v0hJZs3GYpKikkK99a3SHA6dLF1ezuv1mzfG0NLVw/uQr+NuyGYRCoYT9Jf1cZC6u9iQgzimnGzTchSv7KRaqTGrdZoZVPoIf+Q+snQ4G9LsMr2Bot2oOnPCe8dtLUzvGFY+CPCCKysI01ce/W495Rriw7XZuzjkccP+Vj3fok+yt3gAWzPmAk0edydcOGc01r17M3Zc+xL8eraKotJDDTjuYo359eIf+BeFQ0mN+dWvqWFS1RHOY54hbcyFJhfiG/s3vYaHU5jbyCneBipkpVtZzeIU74RfsBC3vd24sGI/X94dp25aCPCD2PWoCz876R8z2Pz53PtuN3poTtv/5xtuzJXOVZzwbhkfmPfs2D13zd8669XS4NXb/oSMGM2ybwfz3vc8SrttvdbheePPsvNGa6kU5uoVfV9igB3FrL4HGB4EWoA/0vx2vePe0bkdj5AFx0qXHURCOPgwxftLu7H7Arix4/QP8DNxMO7K+mUeue5Iz9jiHd1+Nf2u93z9wFn0rEg8FFYRD7LhH/LnTJTOci5DqpboW3jEzxfRwZoV4/S7CG/oe3tBFeEP/nfYQBwV5YAwaNoA7l9zIyK99OV90UWkhv/jzqVz6xG8xM2qrV+O3dm0v1zzjmlcvjjsv+QfzlvCrfS/g1wdOi9ln65234N5Pb2G73UfE3d7vHzq709zmkiV+qvPF98NCQzJSiqSHhlYCpHL4IG6aewXQdo7q5qeE7br3Tl0+L9ULeYzYbSt2nbAT7yS4ofXbL/2H5+95hYOO2ydqe2FRmJurruBb4aNxUf5fGTluW/aalP69EkmSN4C2oZIk3ysVyc3hI7mjPfKA2hDiKz5dyT8fm8uHb3/MVjsNZ9+j9sILpf5nDRV4PHvHPzj4+OQOaP3xh9cnrG927SwGDO3fYfn+x0zgpjf+mHJ9kj5mHliCoRIbDMXHweB38Aq2yk5h0mXaIw8o3/e5+tRbeOHuV/BCIZzvs/UuW3LZk78lXBTmqdtfiHqws29FOXVf1Hcagok0NvPqQ3PYeufhSdcwc+rdnHTpD2K29+lbxv2f30prayuRxgglfUqS/wUls0qPhPo/xGk/Bq/859mrR7pFe+QBde9ls3l65os0N7XQ1NBEZH0zH8xbwu8Pv5wp15/EjntsT3FZEQBmUFRaxEmXHceFD59NYUn0uS7e++dC1q6qS/oqvoeveyqpfqFQSCGeZ6zkm/E7JJwvRfKJ9sgDaNa0v3H3RQ9GbXt/zmJWfLKS6f+4kBfvfpWXH/wXffqXcdhpBzN6311wzlExfCCfLfy803NbW1qpX9tAYUkhTZvc0zMWX6cPBpYVbI/zdgQ/xhW2oeQ/mUnuaY88YO644N6YIb7Bi/e8RmFRmIknHcAfnpzK1HvOZPS+bXdlMTMqhw+M+dz61fVMnjKRwpLChGPt+3z366n/ApI3rPJBYECUlmKs9MdZrka6Q3vkAfLq7Nf568WzE/Zrbop9Beiyj5bz5ouxJ7bfdswIfnL5D/nWj/dnzt//TWNdI3+95EHcZrMfhgpDMafElWAwK4LBT+G++AU0vwUWAsLQdxpWODrX5UkKLB3TKJrZx8A62qbyanHOxb3P17hx41xVVVW3t9ubOOeYVHJcUjeQuPKFCxizf/T5wM879BKqnnk75nMtZDwT+VuncfKbfjmLJ2c8h3OOCUeO5+xZUygIaz+gp3Cty8FfCwUjMAvnupy84De9BXVXgvWB8rPwwjvkuiTMbF60fE1nkI9zzq1Mpr+CPHUfzf+EU796VsJ+/Qb35YFlt8U8YHlYnx/Q1BB/jo29Dh/HRY+c06U6RYLOb2mAlWOBzY4BFe6PN/CWnNS0Qawg1y5VgJhnCedP+fO8K+KedZLMTR5efyL2Ld9EeiLnr8HVz4LmRRB5LnqnyEv461/BK45+IVwupetgpwOeNbN5ZnZqtA5mdqqZVZlZVU1NTZo223uM2GVL+sWZw2Sb0Vsxa9F1VAyPf6/MHcZtl3Bb3Z1sSyRI/Lo7cSv2gPobY4f4Buuuyk5RKUpXkE9wzo0FDgV+Zmad/styzs1wzo1zzo2rrExuXmP5kplx8WPnUljccfwyVOAx4+0/MePN6QzffljC9Zxx9YkJJ7IbPjLxekR6Ar/pP1CXwo0zXKrz1GRHWsbIO6zQbBpQ55z7U6w+GiPvuvo19bx8/7/4fMlyvrrvKPb41pjUbsMFvPvaAq488SaWfVgdtX3WB9czfLtedhMA6ZX8FYeC/2HyTyibild+QuYKSiBjBzvNrAzwnHPr2n9+DrjIOfd0rOcoyPPHrPPv44Hpj9MSaWGb3bZi2uzfMHTE4FyXJXH4retg/ZPgVWDF++gskxT5Ta9D3fVAATTPodNBzThsyMKUd5zSKZNBvi3wcPvDAuAe59yl8Z6jIBfpGr/660DtJksMBszEK5qQq5ICwzkft+J/wKV6Uw0Ag4q5eAWdb2CeTRk7a8U5twTQ1QMiGeRcBLc82rUBDr44CTf4TcwrzXpdQeLqrutiiA/GG/pa2utJJ12iLxIAbvlX47XiGjVneEL1s7r2vAFXpLWMTFCQi+Q5v24WCcdxWz7OQiVBl/zNpjcqOhKv6BvpLyXNFOQi+a7hzsR9So7MfB2A76/Db/4Y5xJfWJZ3wnsm7lP6UwhtD+E9sf63YP0vz3xdaaArO0XyXnGC9hK8wuhz66SL31IDKw8B6oG2KwAdQ2Hwi3heMGLE+l2IW3lQnB5FeH1/BfwqWyWljfbIRfJd+Wlxm23IWxndvHMOVk5gQ4h/qRpW7JHRbaeTFWwFFS8TM/b635TVetJJQS6S56z4MAhF2+OuwBu6KOPnNbu1cW4JRz1+/X04F3vq5HziFQzDG/o+lJzMxvizQTBgNl5xgrsm5bG0X9mZDJ1HLpIa53xc00vtZ1446PMLvKLs7A371bsB8e4YVQDWBxs4Ewtndoint9PshyIBZuZhxQdC8YE52Hqive0WcKtxtSfD4Nd0pWkOaGhFRBLon2S/CETeyGQhEoOCXETi63tukh0N3OYHRCUbFOQiEpdXegSUnJi4o2uGwvEZr0c6U5CLSEJev/Owwf/GBtwFgx5ru7jGSja0AsVQ/hvM65/DKnsvHewUkaSY1weK9sQAN/AvsP5Z3PpnwOuLlR6NhXfLdYm9loJcRFJmVgAlk7CSSbkuRVCQi0ie8CPzoe7qtgnAvGEQqgAMwjthJd/BQrpFZCwKchHJGb95CaydCs1vAy2bNHz65cOmv+PqpuMogZLJUH42ntcnF+XmLR3sFJGc8Jv+BasOheZ5dAjxmBqh8T5YMRa/eix+w4OZLjEwFOQiknXOOVj9c9rmUeyKOlj7W/zl38RvrUtnaYGkIBeR7Gv9L7h13V+PWw41Y/HX5/et2DJNQS4iOWB0fW88itUn4fzeu2euIBeR7AttRVuYp49bnexUAj2PglxEss7MwKtI70ojL6R3fQGiIBeR3Cj9YZpX2IpzyZz90vMoyEUkJ6zsZCjcJ81rzf6NcvKBglxEcsKsEG/gbdigRyGchhtmhLbttTe10JWdIpJTFt4ZG3QzzjXiGl+Ehr9By1za9q5DgA+0JlhLEQyYkfFa85WCXETyglkJVvptKP02zrVCy3uABwU7Y+a1Xc5ffy80zwG/CawJrD+UHIaV/QDbOK1u76MgF5G8YxaCzabF9cLbQv+pOaoov2mMXEQk4BTkInnMr7sfv3pX/Ood8ZcfgB95P9clSR7S0IpInvKrvw7UfrnAfQa1h+P3uw2vJN2n7UmQaY9cJA/51XvRIcQ3teZnWa1F8l9agtzMJprZQjNbbGa9d8IDkTTw110PrIrToylbpUhAdDvIzSwE3AgcCowCvm9mo7q7XpFeq/7Pua5AAiYde+TjgcXOuSXOuQhwHzA5DesV6aWaE7T3zUoVEhzpCPLhwKebPP6sfZmIdIUNiN9e8VJ26pDASEeQR5tUuNPMNWZ2qplVmVlVTU1NGjYr0kP1uzh228C38ArKs1eLBEI6gvwzYMtNHm8BfL55J+fcDOfcOOfcuMrKyjRsVqRn8ooPgfIrgOIvF4a+CpUL8ApLc1aX5K90nEc+FxhpZtsAS4FjgePSsF6RXssrOwLKjsC51rbL1UXi6HaQO+dazGwK8AxtU5XNdM79p9uViYhCXJKSlis7nXNPAk+mY10iIpIaXdkpIhJwCnIRkYBTkIuIBJyCXEQk4BTkIiIBpyAXEQk4BbmISMApyEVEAk5BLiIScApyEZGAU5CLiAScglxEJOAU5CIiAacgFxEJOAW5iEjAKchFRAJOQS4iEnAKchGRgFOQi4gEnIJcRCTgFOQiIgGnIBcRCTgFuYhIwCnIRUQCTkEuIhJwCnIRkYBTkItIQn7LMvzIAnzfz3UpEkVBrgsQkfzk/Frcmhug6a8dlvslP8Lr9/scVSXRKMhFpAPnHG7tZdB4R/QOjXfhh8filX47u4VJTBpaEZEOXMM9sUN8g7VTs1OMJEV75CLSUd0NSXRqTGpVzq+FyFywvlA4HrNQ92qTqBTkItKRW5NEp7KEPfy6GVB3FfDlAVJXNBlvwJVdr02i0tCKiHRkfRP36X9L3GYXeQPqprNpiAPQ9Ch+9UFdr02i6laQm9k0M1tqZm+1f01KV2EikiN9TovfXnI6XvEecbu4ujsBF6P1E/zqr3WpNIkuHXvkVzvnxrR/PZmG9YlIDlnpCVA0MUpLH6iYg9fvl4lX4i9N0GEdfu25XSlPotAYuYh0YOZhA67DNX8AzXNxVg5FB+B5icfFNyqaBC3/id8nMhvnLsFMMdRd6dgjn2Jm75jZTDMbEKuTmZ1qZlVmVlVTU5OGzYpIJll4JFZ6HF7J/6QW4oD1OQGwxB1bq7tWnHSQMMjN7Hkzmx/lazJwM7AdMAZYBkyPtR7n3Azn3Djn3LjKysp01S+SE/7aG/Crd8OvHoW/8of4rdo52ZRZIVS8krij1z/jtfQGCT/TOOeSOsRsZrcCT3S7IpE851fv0HFByxtQszd+5ct4oaG5KSoPeQVD8Cveg5Wjonco2g/z+mS3qB6qu2etDNvk4ZHA/O6VI5LfOoX4Rg5qT81qLUHgFRRgQxaCt3PHhsK9sf7X5qaoHqi7RxmuMLMxtJ1n9DGQ4LwlkeDyG56O36F1YXYKCRgzwwY/inNN0PIJhCowL+bhNOmCbgW5c+5H6SpEJO/VxTwEJEkwK4LwyFyX0SPpyk6RZNnA+O2Fe2enDpHNKMhFktX/8rjNNuC2LBUi0pGCXCRJXngbCB8avW3oIsySOG9aJAMU5CIp8AZdC4NegIJx4G0L/WbgDV2U67Kkl9O1sSIp8sJbQsU9uS5DZCPtkYuIBJyCXEQk4BTkIiIBpyAXEQk4BbmISMCZc7Fux5TBjZrVAP/N4iYrgJVZ3F46BLFmCGbdqjk7VHP3be2c6zQPeE6CPNvMrMo5Ny7XdaQiiDVDMOtWzdmhmjNHQysiIgGnIBcRCbjeEuQzcl1AFwSxZghm3ao5O1RzhvSKMXIRkZ6st+yRi4j0WApyEZGA69FBbmZHmdl/zMw3s3GbtZ1nZovNbKGZfStXNcZjZtPMbKmZvdX+NSnXNcViZhPbX8vFZnZurutJhpl9bGbvtr+2VbmuJxYzm2lmK8xs/ibLBprZc2b2Qfv3vLoJZoya8/r9bGZbmtlLZragPTd+0b48r19r6OFBDswHvgO8sulCMxsFHAvsAkwEbjKzUPbLS8rVzrkx7V9P5rqYaNpfuxuBQ4FRwPfbX+Mg2L/9tc3nc4Vn0fY+3dS5wAvOuZHAC+2P88ksOtcM+f1+bgHOcs7tDHwd+Fn7+zjfX+ueHeTOuQXOuWi3Np8M3Oeca3LOfQQsBsZnt7oeZTyw2Dm3xDkXAe6j7TWWNHDOvQLUbrZ4MnBH+893AEdks6ZEYtSc15xzy5xz/27/eR2wABhOnr/W0MODPI7hwKebPP6sfVk+mmJm77R/VM27j3TtgvR6bsoBz5rZPDM7NdfFpGiIc24ZtAUQMDjH9SQrCO9nzGwEsDswhwC81oEPcjN73szmR/mKt0cY7eaKOTkPM0H9NwPbAWOAZcD0XNSYhLx5PVM0wTk3lrYhoZ+Z2T65LqiHC8T72cz6AA8BZzrn1ua6nmQE/lZvzrmDuvC0z4AtN3m8BfB5eipKTbL1m9mtwBMZLqer8ub1TIVz7vP27yvM7GHahoheif+svLHczIY555aZ2TBgRa4LSsQ5t3zDz/n6fjazMG0hfrdzbnb74rx/rQO/R95FjwHHmlmRmW0DjATeyHFNnbS/aTY4kraDt/loLjDSzLYxs0LaDiQ/luOa4jKzMjMr3/AzcAj5+/pG8xhwQvvPJwCP5rCWpOT7+9nMDLgdWOCcu2qTprx/rXv0lZ1mdiRwPVAJrAbecs59q71tKnASbUeqz3TOPZWrOmMxs7to+xjqgI+B0zaM1eWb9lPJrgFCwEzn3KW5rSg+M9sWeLj9YQFwT77WbGb3AvvRNqXqcuAC4BHgfmAr4BPgKOdc3hxcjFHzfuTx+9nM9gZeBd4F/PbFv6VtnDxvX2vo4UEuItIb9NahFRGRHkNBLiIScApyEZGAU5CLiAScglxEJOAU5CIiAacgFxEJuP8HK5Kn0SwIB/oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding[:,0], embedding[:,1], c=df[\"embedding_approach_tsne\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
